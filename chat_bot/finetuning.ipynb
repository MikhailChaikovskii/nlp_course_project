{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\chayk\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\daily_dialog\\1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd (last modified on Mon Jun  3 01:14:33 2024) since it couldn't be found locally at daily_dialog, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "# load the dataset for fine-tuning\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load DailyDialog dataset\n",
    "dataset = load_dataset(\"daily_dialog\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load initial model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer for DialoGPT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|UNK|>',\n",
       " 'pad_token': '<|PAD|>'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '<|PAD|>'})\n",
    "tokenizer.add_special_tokens({'unk_token': '<|UNK|>'})\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    input_ids_list = []\n",
    "    for dialog in examples['dialog']:\n",
    "        full_conversation = \"\"\n",
    "        for turn in dialog:\n",
    "            full_conversation += turn + tokenizer.eos_token\n",
    "        input_ids = tokenizer(full_conversation, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
    "        input_ids_list.append(input_ids.squeeze())\n",
    "\n",
    "    return {\"input_ids\": input_ids_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b43a8c3d83469fa81cdbfce58866ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11118 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02627ed5f36e4f2aa42b19853b9fa3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "train_dataset = dataset[\"train\"].map(preprocess_function, batched=True, remove_columns=[\"dialog\", \"act\", \"emotion\"])\n",
    "valid_dataset = dataset[\"validation\"].map(preprocess_function, batched=True, remove_columns=[\"dialog\", \"act\", \"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 50259\n",
      "Model's embedding layer size: 50259\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the pre-trained DialoGPT model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\").to(device)\n",
    "# Resize the token embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Check the number of tokens\n",
    "print(f\"Tokenizer vocab size: {len(tokenizer)}\")\n",
    "print(f\"Model's embedding layer size: {model.transformer.wte.num_embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\my_ml_env\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78eec3456574180937af2e04482f6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37060 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6752, 'grad_norm': 1.4994325637817383, 'learning_rate': 4.932811656772801e-05, 'epoch': 0.13}\n",
      "{'loss': 2.4475, 'grad_norm': 1.636724591255188, 'learning_rate': 4.865353480841878e-05, 'epoch': 0.27}\n",
      "{'loss': 2.3843, 'grad_norm': 1.6692636013031006, 'learning_rate': 4.7978953049109555e-05, 'epoch': 0.4}\n",
      "{'loss': 2.3553, 'grad_norm': 1.7826321125030518, 'learning_rate': 4.7304371289800323e-05, 'epoch': 0.54}\n",
      "{'loss': 2.3392, 'grad_norm': 1.679495930671692, 'learning_rate': 4.66297895304911e-05, 'epoch': 0.67}\n",
      "{'loss': 2.2918, 'grad_norm': 2.038083076477051, 'learning_rate': 4.595520777118187e-05, 'epoch': 0.81}\n",
      "{'loss': 2.2631, 'grad_norm': 2.4135501384735107, 'learning_rate': 4.528062601187264e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c289febd0c4800b5ee26cff127ac2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1729540824890137, 'eval_runtime': 16.5919, 'eval_samples_per_second': 60.27, 'eval_steps_per_second': 20.13, 'epoch': 1.0}\n",
      "{'loss': 2.1108, 'grad_norm': 1.7540032863616943, 'learning_rate': 4.460604425256341e-05, 'epoch': 1.08}\n",
      "{'loss': 1.9894, 'grad_norm': 1.4170247316360474, 'learning_rate': 4.393146249325418e-05, 'epoch': 1.21}\n",
      "{'loss': 1.9442, 'grad_norm': 1.843526005744934, 'learning_rate': 4.3256880733944956e-05, 'epoch': 1.35}\n",
      "{'loss': 1.9381, 'grad_norm': 2.150355100631714, 'learning_rate': 4.2582298974635725e-05, 'epoch': 1.48}\n",
      "{'loss': 1.9525, 'grad_norm': 1.3762195110321045, 'learning_rate': 4.190906637884512e-05, 'epoch': 1.62}\n",
      "{'loss': 1.9475, 'grad_norm': 2.7121331691741943, 'learning_rate': 4.123448461953589e-05, 'epoch': 1.75}\n",
      "{'loss': 1.9528, 'grad_norm': 2.4378883838653564, 'learning_rate': 4.055990286022666e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72c16a0c077435093e2a0520873ab82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.081174373626709, 'eval_runtime': 16.7597, 'eval_samples_per_second': 59.667, 'eval_steps_per_second': 19.929, 'epoch': 2.0}\n",
      "{'loss': 1.8746, 'grad_norm': 1.822587490081787, 'learning_rate': 3.9885321100917436e-05, 'epoch': 2.02}\n",
      "{'loss': 1.661, 'grad_norm': 1.9174760580062866, 'learning_rate': 3.9210739341608205e-05, 'epoch': 2.16}\n",
      "{'loss': 1.644, 'grad_norm': 2.1313865184783936, 'learning_rate': 3.8536157582298974e-05, 'epoch': 2.29}\n",
      "{'loss': 1.6645, 'grad_norm': 2.2029531002044678, 'learning_rate': 3.7862924986508366e-05, 'epoch': 2.43}\n",
      "{'loss': 1.6484, 'grad_norm': 2.3361639976501465, 'learning_rate': 3.718834322719914e-05, 'epoch': 2.56}\n",
      "{'loss': 1.6649, 'grad_norm': 1.9254432916641235, 'learning_rate': 3.651376146788991e-05, 'epoch': 2.7}\n",
      "{'loss': 1.6621, 'grad_norm': 1.4907162189483643, 'learning_rate': 3.5839179708580685e-05, 'epoch': 2.83}\n",
      "{'loss': 1.6539, 'grad_norm': 2.3692052364349365, 'learning_rate': 3.516594711279007e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870a7242b5be45b39c1846205ba4132e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0699386596679688, 'eval_runtime': 15.983, 'eval_samples_per_second': 62.566, 'eval_steps_per_second': 20.897, 'epoch': 3.0}\n",
      "{'loss': 1.4734, 'grad_norm': 2.053802728652954, 'learning_rate': 3.449136535348084e-05, 'epoch': 3.1}\n",
      "{'loss': 1.388, 'grad_norm': 1.7565886974334717, 'learning_rate': 3.3816783594171615e-05, 'epoch': 3.24}\n",
      "{'loss': 1.4328, 'grad_norm': 2.4003779888153076, 'learning_rate': 3.3142201834862383e-05, 'epoch': 3.37}\n",
      "{'loss': 1.4365, 'grad_norm': 2.6059961318969727, 'learning_rate': 3.246762007555316e-05, 'epoch': 3.51}\n",
      "{'loss': 1.4065, 'grad_norm': 2.2558655738830566, 'learning_rate': 3.179303831624393e-05, 'epoch': 3.64}\n",
      "{'loss': 1.3991, 'grad_norm': 1.6466410160064697, 'learning_rate': 3.1118456556934696e-05, 'epoch': 3.78}\n",
      "{'loss': 1.4209, 'grad_norm': 2.177645206451416, 'learning_rate': 3.0443874797625472e-05, 'epoch': 3.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7354bf44d36b4191a36411496474f1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.084639549255371, 'eval_runtime': 16.2838, 'eval_samples_per_second': 61.411, 'eval_steps_per_second': 20.511, 'epoch': 4.0}\n",
      "{'loss': 1.33, 'grad_norm': 2.782716751098633, 'learning_rate': 2.9769293038316244e-05, 'epoch': 4.05}\n",
      "{'loss': 1.21, 'grad_norm': 1.771601676940918, 'learning_rate': 2.9096060442525636e-05, 'epoch': 4.18}\n",
      "{'loss': 1.2237, 'grad_norm': 3.089996814727783, 'learning_rate': 2.8421478683216408e-05, 'epoch': 4.32}\n",
      "{'loss': 1.2144, 'grad_norm': 3.1457550525665283, 'learning_rate': 2.77482460874258e-05, 'epoch': 4.45}\n",
      "{'loss': 1.2141, 'grad_norm': 2.2372615337371826, 'learning_rate': 2.7073664328116572e-05, 'epoch': 4.59}\n",
      "{'loss': 1.1981, 'grad_norm': 3.337855815887451, 'learning_rate': 2.6399082568807344e-05, 'epoch': 4.72}\n",
      "{'loss': 1.2401, 'grad_norm': 2.7796990871429443, 'learning_rate': 2.5724500809498113e-05, 'epoch': 4.86}\n",
      "{'loss': 1.2638, 'grad_norm': 2.1005067825317383, 'learning_rate': 2.5049919050188885e-05, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f91ebbe99b447a882f61cc8ce9ca51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1702349185943604, 'eval_runtime': 83.9471, 'eval_samples_per_second': 11.912, 'eval_steps_per_second': 3.979, 'epoch': 5.0}\n",
      "{'loss': 1.0464, 'grad_norm': 2.3525736331939697, 'learning_rate': 2.4376686454398273e-05, 'epoch': 5.13}\n",
      "{'loss': 1.0589, 'grad_norm': 2.462818145751953, 'learning_rate': 2.3702104695089045e-05, 'epoch': 5.26}\n",
      "{'loss': 1.0439, 'grad_norm': 2.167367458343506, 'learning_rate': 2.3027522935779818e-05, 'epoch': 5.4}\n",
      "{'loss': 1.0762, 'grad_norm': 3.792766571044922, 'learning_rate': 2.235294117647059e-05, 'epoch': 5.53}\n",
      "{'loss': 1.0807, 'grad_norm': 2.4587132930755615, 'learning_rate': 2.1678359417161362e-05, 'epoch': 5.67}\n",
      "{'loss': 1.08, 'grad_norm': 2.6472761631011963, 'learning_rate': 2.1003777657852134e-05, 'epoch': 5.8}\n",
      "{'loss': 1.0721, 'grad_norm': 2.4320342540740967, 'learning_rate': 2.0329195898542906e-05, 'epoch': 5.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bd120e887b483faf9e4d4801dedf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.210801839828491, 'eval_runtime': 16.1565, 'eval_samples_per_second': 61.895, 'eval_steps_per_second': 20.673, 'epoch': 6.0}\n",
      "{'loss': 1.0009, 'grad_norm': 2.898427724838257, 'learning_rate': 1.9654614139233675e-05, 'epoch': 6.07}\n",
      "{'loss': 0.9182, 'grad_norm': 3.0798768997192383, 'learning_rate': 1.8980032379924447e-05, 'epoch': 6.21}\n",
      "{'loss': 0.9398, 'grad_norm': 1.964685320854187, 'learning_rate': 1.830679978413384e-05, 'epoch': 6.34}\n",
      "{'loss': 0.9518, 'grad_norm': 2.135767936706543, 'learning_rate': 1.763221802482461e-05, 'epoch': 6.48}\n",
      "{'loss': 0.9722, 'grad_norm': 2.859252691268921, 'learning_rate': 1.695763626551538e-05, 'epoch': 6.61}\n",
      "{'loss': 0.9364, 'grad_norm': 3.469951868057251, 'learning_rate': 1.628440366972477e-05, 'epoch': 6.75}\n",
      "{'loss': 0.9481, 'grad_norm': 2.934156656265259, 'learning_rate': 1.5609821910415543e-05, 'epoch': 6.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f45b4f5e4fc46e08eb7cfa5a8556bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2848682403564453, 'eval_runtime': 19.0798, 'eval_samples_per_second': 52.411, 'eval_steps_per_second': 17.505, 'epoch': 7.0}\n",
      "{'loss': 0.9451, 'grad_norm': 2.9964892864227295, 'learning_rate': 1.4935240151106314e-05, 'epoch': 7.02}\n",
      "{'loss': 0.8308, 'grad_norm': 2.728847026824951, 'learning_rate': 1.4260658391797086e-05, 'epoch': 7.15}\n",
      "{'loss': 0.8569, 'grad_norm': 2.8133859634399414, 'learning_rate': 1.3586076632487856e-05, 'epoch': 7.29}\n",
      "{'loss': 0.8366, 'grad_norm': 5.522408962249756, 'learning_rate': 1.2911494873178632e-05, 'epoch': 7.42}\n",
      "{'loss': 0.8503, 'grad_norm': 2.4129326343536377, 'learning_rate': 1.22369131138694e-05, 'epoch': 7.56}\n",
      "{'loss': 0.8674, 'grad_norm': 2.2248663902282715, 'learning_rate': 1.156368051807879e-05, 'epoch': 7.69}\n",
      "{'loss': 0.8539, 'grad_norm': 3.3896520137786865, 'learning_rate': 1.0889098758769563e-05, 'epoch': 7.83}\n",
      "{'loss': 0.8593, 'grad_norm': 2.343238592147827, 'learning_rate': 1.0214516999460335e-05, 'epoch': 7.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e40c2d0e7e482881865388c5da7fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.35844087600708, 'eval_runtime': 17.0463, 'eval_samples_per_second': 58.664, 'eval_steps_per_second': 19.594, 'epoch': 8.0}\n",
      "{'loss': 0.8056, 'grad_norm': 2.8924620151519775, 'learning_rate': 9.539935240151107e-06, 'epoch': 8.09}\n",
      "{'loss': 0.781, 'grad_norm': 3.091989040374756, 'learning_rate': 8.86535348084188e-06, 'epoch': 8.23}\n",
      "{'loss': 0.7886, 'grad_norm': 2.7378833293914795, 'learning_rate': 8.19077172153265e-06, 'epoch': 8.36}\n",
      "{'loss': 0.7863, 'grad_norm': 2.4306893348693848, 'learning_rate': 7.516189962223422e-06, 'epoch': 8.5}\n",
      "{'loss': 0.7893, 'grad_norm': 2.9339637756347656, 'learning_rate': 6.841608202914193e-06, 'epoch': 8.63}\n",
      "{'loss': 0.7997, 'grad_norm': 2.296724319458008, 'learning_rate': 6.168375607123584e-06, 'epoch': 8.77}\n",
      "{'loss': 0.7804, 'grad_norm': 2.2409121990203857, 'learning_rate': 5.493793847814355e-06, 'epoch': 8.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0021b6434c45408859ae5f10a6a831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.405756950378418, 'eval_runtime': 16.5721, 'eval_samples_per_second': 60.342, 'eval_steps_per_second': 20.154, 'epoch': 9.0}\n",
      "{'loss': 0.7721, 'grad_norm': 2.5153489112854004, 'learning_rate': 4.819212088505127e-06, 'epoch': 9.04}\n",
      "{'loss': 0.7424, 'grad_norm': 3.14442777633667, 'learning_rate': 4.144630329195899e-06, 'epoch': 9.17}\n",
      "{'loss': 0.7445, 'grad_norm': 2.7694032192230225, 'learning_rate': 3.4700485698866704e-06, 'epoch': 9.31}\n",
      "{'loss': 0.7278, 'grad_norm': 2.410040855407715, 'learning_rate': 2.7968159740960605e-06, 'epoch': 9.44}\n",
      "{'loss': 0.7234, 'grad_norm': 2.927440881729126, 'learning_rate': 2.122234214786832e-06, 'epoch': 9.58}\n",
      "{'loss': 0.7547, 'grad_norm': 2.010244131088257, 'learning_rate': 1.447652455477604e-06, 'epoch': 9.71}\n",
      "{'loss': 0.7477, 'grad_norm': 2.601353406906128, 'learning_rate': 7.730706961683757e-07, 'epoch': 9.85}\n",
      "{'loss': 0.7347, 'grad_norm': 2.679176092147827, 'learning_rate': 1.0118726389638424e-07, 'epoch': 9.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60089da933f419d9e12008c07d31351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4457435607910156, 'eval_runtime': 14.4988, 'eval_samples_per_second': 68.971, 'eval_steps_per_second': 23.036, 'epoch': 10.0}\n",
      "{'train_runtime': 7181.676, 'train_samples_per_second': 15.481, 'train_steps_per_second': 5.16, 'train_loss': 1.3019859219266476, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37060, training_loss=1.3019859219266476, metrics={'train_runtime': 7181.676, 'train_samples_per_second': 15.481, 'train_steps_per_second': 5.16, 'total_flos': 4.163011146429235e+16, 'train_loss': 1.3019859219266476, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-dialogpt_new\\\\tokenizer_config.json',\n",
       " './fine-tuned-dialogpt_new\\\\special_tokens_map.json',\n",
       " './fine-tuned-dialogpt_new\\\\vocab.json',\n",
       " './fine-tuned-dialogpt_new\\\\merges.txt',\n",
       " './fine-tuned-dialogpt_new\\\\added_tokens.json',\n",
       " './fine-tuned-dialogpt_new\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./models/fine-tuned-dialogpt_new\")\n",
    "tokenizer.save_pretrained(\"./models/fine-tuned-dialogpt_new\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
